{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "任何策略的本质都是在预测，一次预测包括用来预测的因子、被预测的变量、预测模型。预测是一个研究过程，包括不断调整\n",
    "预测因子和预测模型，以获得最小的错误率\n",
    "\n",
    "下面选定分钟bar的涨跌作为被预测变量，选定非常细粒度的数据的好处在于，可以快速的累积到足够多的样本数据。 缺点在于，越是高粒度\n",
    "的数据，其规律越接近于随机游走，所以发现有效模型的概率越低。 关于预测因子，在高频交易的情况下，由于不需要考虑基本面的数据，所以\n",
    "预测因子基本上也是过去的回报。为了预测一分钟的回报方向，选定过去1、3、5分钟的回报作为预测因子，模型上选用逻辑回归模型。预测因子\n",
    "可以尝试下连续型和离散型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from se2.domain.time_series import *\n",
    "from se2.domain.engine import *\n",
    "from se2.domain.account import *\n",
    "from se2.domain.common import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         start_time   open   high    low  \\\nvisible_time                                                               \n2021-05-10 21:31:00+08:00 2021-05-10 21:30:00+08:00  19.58  19.59  19.32   \n2021-05-10 21:32:00+08:00 2021-05-10 21:31:00+08:00  19.39  19.39  19.12   \n2021-05-10 21:33:00+08:00 2021-05-10 21:32:00+08:00  19.15  19.35  19.07   \n2021-05-10 21:34:00+08:00 2021-05-10 21:33:00+08:00  19.30  19.45  19.29   \n2021-05-10 21:35:00+08:00 2021-05-10 21:34:00+08:00  19.37  19.38  19.27   \n\n                           close  volume  \nvisible_time                              \n2021-05-10 21:31:00+08:00  19.41    1624  \n2021-05-10 21:32:00+08:00  19.16     387  \n2021-05-10 21:33:00+08:00  19.30     432  \n2021-05-10 21:34:00+08:00  19.41     299  \n2021-05-10 21:35:00+08:00  19.27     190  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 21:31:00+08:00</th>\n      <td>2021-05-10 21:30:00+08:00</td>\n      <td>19.58</td>\n      <td>19.59</td>\n      <td>19.32</td>\n      <td>19.41</td>\n      <td>1624</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:32:00+08:00</th>\n      <td>2021-05-10 21:31:00+08:00</td>\n      <td>19.39</td>\n      <td>19.39</td>\n      <td>19.12</td>\n      <td>19.16</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:33:00+08:00</th>\n      <td>2021-05-10 21:32:00+08:00</td>\n      <td>19.15</td>\n      <td>19.35</td>\n      <td>19.07</td>\n      <td>19.30</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:34:00+08:00</th>\n      <td>2021-05-10 21:33:00+08:00</td>\n      <td>19.30</td>\n      <td>19.45</td>\n      <td>19.29</td>\n      <td>19.41</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:35:00+08:00</th>\n      <td>2021-05-10 21:34:00+08:00</td>\n      <td>19.37</td>\n      <td>19.38</td>\n      <td>19.27</td>\n      <td>19.27</td>\n      <td>190</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = 'SPCE_STK_USD_SMART'\n",
    "start = pd.Timestamp('2021-05-09 21:00:00', tz='Asia/Shanghai')\n",
    "end = pd.Timestamp('2021-06-09 21:00:00', tz='Asia/Shanghai')\n",
    "command = HistoryDataQueryCommand(start, end, [code])\n",
    "ts_repo: TimeSeriesRepo = BeanContainer.getBean(TimeSeriesRepo)\n",
    "ts: TimeSeries = ts_repo.find_one(\"ibMinBar\")\n",
    "MIN_BAR_DF: DataFrame = ts.history_data(command, from_local=True)\n",
    "MIN_BAR_DF = MIN_BAR_DF.droplevel(level=1)\n",
    "MIN_BAR_DF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# 构造训练集和验证集\n",
    "df = MIN_BAR_DF[:'2021-05-11 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5, \"next_ret1\": next_ret1})\n",
    "train_data = df.dropna()\n",
    "train_data = train_data[train_data['next_ret1']!=0]\n",
    "train_data.loc[train_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "train_data.loc[train_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "df = MIN_BAR_DF['2021-05-11 21:00:00':'2021-05-12 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5, \"next_ret1\": next_ret1})\n",
    "test_data = df.dropna()\n",
    "test_data = test_data[test_data['next_ret1']!=0]\n",
    "test_data.loc[test_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "test_data.loc[test_data['next_ret1']<0, 'next_ret1'] = -1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhang/opt/miniconda3/envs/strategy-engine/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 0])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.predict(X[:2, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.81802911e-01, 1.81970751e-02, 1.43580537e-08],\n       [9.71729527e-01, 2.82704429e-02, 3.00353141e-08]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[:2, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9733333333333334"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.45938375350140054"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = train_data['next_ret1'].values\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X, y)\n",
    "X_t = test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = test_data['next_ret1'].values\n",
    "lr.score(X_t, y_t)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "count    696.000000\nmean       0.000310\nstd        0.007099\nmin       -0.030332\n25%       -0.003239\n50%        0.000000\n75%        0.003449\nmax        0.044397\nName: pre_ret5, dtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_data['pre_ret5'], test_data['pre_ret5']]).describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# 尝试使用离散的变量\n",
    "new_train_data = train_data.copy()\n",
    "new_train_data.loc[:,'pre_ret1'] = pd.qcut(new_train_data['pre_ret1'], 2, labels=[-1, 1])\n",
    "new_train_data.loc[:,'pre_ret3'] = pd.qcut(new_train_data['pre_ret3'], 2, labels=[-1, 1])\n",
    "new_train_data.loc[:,'pre_ret5'] = pd.qcut(new_train_data['pre_ret5'], 2, labels=[-1, 1])\n",
    "\n",
    "new_test_data = test_data.copy()\n",
    "new_test_data.loc[:,'pre_ret1'] = pd.qcut(new_test_data['pre_ret1'], 2, labels=[-1, 1])\n",
    "new_test_data.loc[:,'pre_ret3'] = pd.qcut(new_test_data['pre_ret3'], 2, labels=[-1, 1])\n",
    "new_test_data.loc[:,'pre_ret5'] = pd.qcut(new_test_data['pre_ret5'], 2, labels=[-1, 1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5210084033613446"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = new_train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = new_train_data['next_ret1'].values\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X, y)\n",
    "X_t = new_test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = new_test_data['next_ret1'].values\n",
    "lr.score(X_t, y_t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         start_time   open   high    low  \\\nvisible_time                                                               \n2021-05-10 21:31:00+08:00 2021-05-10 21:30:00+08:00  19.58  19.59  19.32   \n2021-05-10 21:32:00+08:00 2021-05-10 21:31:00+08:00  19.39  19.39  19.12   \n2021-05-10 21:33:00+08:00 2021-05-10 21:32:00+08:00  19.15  19.35  19.07   \n2021-05-10 21:34:00+08:00 2021-05-10 21:33:00+08:00  19.30  19.45  19.29   \n2021-05-10 21:35:00+08:00 2021-05-10 21:34:00+08:00  19.37  19.38  19.27   \n...                                             ...    ...    ...    ...   \n2021-05-11 03:56:00+08:00 2021-05-11 03:55:00+08:00  17.92  17.97  17.91   \n2021-05-11 03:57:00+08:00 2021-05-11 03:56:00+08:00  17.97  17.98  17.97   \n2021-05-11 03:58:00+08:00 2021-05-11 03:57:00+08:00  17.98  17.98  17.90   \n2021-05-11 03:59:00+08:00 2021-05-11 03:58:00+08:00  17.91  17.94  17.90   \n2021-05-11 04:00:00+08:00 2021-05-11 03:59:00+08:00  17.94  17.98  17.93   \n\n                           close  volume  \nvisible_time                              \n2021-05-10 21:31:00+08:00  19.41    1624  \n2021-05-10 21:32:00+08:00  19.16     387  \n2021-05-10 21:33:00+08:00  19.30     432  \n2021-05-10 21:34:00+08:00  19.41     299  \n2021-05-10 21:35:00+08:00  19.27     190  \n...                          ...     ...  \n2021-05-11 03:56:00+08:00  17.96     875  \n2021-05-11 03:57:00+08:00  17.98     481  \n2021-05-11 03:58:00+08:00  17.91    1459  \n2021-05-11 03:59:00+08:00  17.94     489  \n2021-05-11 04:00:00+08:00  17.97    1426  \n\n[390 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 21:31:00+08:00</th>\n      <td>2021-05-10 21:30:00+08:00</td>\n      <td>19.58</td>\n      <td>19.59</td>\n      <td>19.32</td>\n      <td>19.41</td>\n      <td>1624</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:32:00+08:00</th>\n      <td>2021-05-10 21:31:00+08:00</td>\n      <td>19.39</td>\n      <td>19.39</td>\n      <td>19.12</td>\n      <td>19.16</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:33:00+08:00</th>\n      <td>2021-05-10 21:32:00+08:00</td>\n      <td>19.15</td>\n      <td>19.35</td>\n      <td>19.07</td>\n      <td>19.30</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:34:00+08:00</th>\n      <td>2021-05-10 21:33:00+08:00</td>\n      <td>19.30</td>\n      <td>19.45</td>\n      <td>19.29</td>\n      <td>19.41</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:35:00+08:00</th>\n      <td>2021-05-10 21:34:00+08:00</td>\n      <td>19.37</td>\n      <td>19.38</td>\n      <td>19.27</td>\n      <td>19.27</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:56:00+08:00</th>\n      <td>2021-05-11 03:55:00+08:00</td>\n      <td>17.92</td>\n      <td>17.97</td>\n      <td>17.91</td>\n      <td>17.96</td>\n      <td>875</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:57:00+08:00</th>\n      <td>2021-05-11 03:56:00+08:00</td>\n      <td>17.97</td>\n      <td>17.98</td>\n      <td>17.97</td>\n      <td>17.98</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:58:00+08:00</th>\n      <td>2021-05-11 03:57:00+08:00</td>\n      <td>17.98</td>\n      <td>17.98</td>\n      <td>17.90</td>\n      <td>17.91</td>\n      <td>1459</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:59:00+08:00</th>\n      <td>2021-05-11 03:58:00+08:00</td>\n      <td>17.91</td>\n      <td>17.94</td>\n      <td>17.90</td>\n      <td>17.94</td>\n      <td>489</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 04:00:00+08:00</th>\n      <td>2021-05-11 03:59:00+08:00</td>\n      <td>17.94</td>\n      <td>17.98</td>\n      <td>17.93</td>\n      <td>17.97</td>\n      <td>1426</td>\n    </tr>\n  </tbody>\n</table>\n<p>390 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_BAR_DF[:'2021-05-11 21:00:00']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data score with svc:0.5688622754491018\n",
      "train data score with lr:0.562874251497006\n",
      "test data score with svc:0.547752808988764\n",
      "test data score with lr:0.5224719101123596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "discretization_count = 2\n",
    "labels = [-1, 1]\n",
    "\n",
    "df = MIN_BAR_DF[:'2021-05-11 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "pre_ret10 = np.log(df['close'] / df['close'].shift(10))\n",
    "pre_volume1 = df['volume']\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5,\n",
    "                   \"pre_volume1\": pre_volume1,\n",
    "                   \"pre_ret10\": pre_ret10,\n",
    "                   \"next_ret1\": next_ret1})\n",
    "train_data = df.dropna()\n",
    "train_data = train_data[train_data['next_ret1']!=0]\n",
    "train_data.loc[train_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "train_data.loc[train_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "df = MIN_BAR_DF['2021-05-11 21:00:00':'2021-05-12 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "pre_ret10 = np.log(df['close'] / df['close'].shift(10))\n",
    "pre_volume1 = df['volume']\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5,\n",
    "                   \"pre_volume1\": pre_volume1,\n",
    "                   \"pre_ret10\": pre_ret10,\n",
    "                   \"next_ret1\": next_ret1})\n",
    "test_data = df.dropna()\n",
    "test_data = test_data[test_data['next_ret1']!=0]\n",
    "test_data.loc[test_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "test_data.loc[test_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "\n",
    "new_train_data = train_data.copy()\n",
    "new_train_data.loc[:,'pre_ret1'] = pd.qcut(new_train_data['pre_ret1'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret3'] = pd.qcut(new_train_data['pre_ret3'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret5'] = pd.qcut(new_train_data['pre_ret5'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_volume1'] = pd.qcut(new_train_data['pre_volume1'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret10'] = pd.qcut(new_train_data['pre_ret10'], discretization_count, labels=labels)\n",
    "\n",
    "new_test_data = test_data.copy()\n",
    "new_test_data.loc[:,'pre_ret1'] = pd.qcut(new_test_data['pre_ret1'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret3'] = pd.qcut(new_test_data['pre_ret3'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret5'] = pd.qcut(new_test_data['pre_ret5'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_volume1'] = pd.qcut(new_test_data['pre_volume1'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret10'] = pd.qcut(new_test_data['pre_ret10'], discretization_count, labels=labels)\n",
    "\n",
    "\n",
    "X = new_train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = new_train_data['next_ret1'].values\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(\"train data score with svc:{}\".format(model.score(X, y)))\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X, y)\n",
    "print(\"train data score with lr:{}\".format(model2.score(X, y)))\n",
    "X_t = new_test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = new_test_data['next_ret1'].values\n",
    "print(\"test data score with svc:{}\".format(model.score(X_t, y_t)))\n",
    "print(\"test data score with lr:{}\".format(model2.score(X_t, y_t)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}