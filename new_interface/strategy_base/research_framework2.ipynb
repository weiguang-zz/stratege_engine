{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "任何策略的本质都是在预测，一次预测包括用来预测的因子、被预测的变量、预测模型。预测是一个研究过程，包括不断调整\n",
    "预测因子和预测模型，以获得最小的错误率\n",
    "\n",
    "下面选定分钟bar的涨跌作为被预测变量，选定非常细粒度的数据的好处在于，可以快速的累积到足够多的样本数据。 缺点在于，越是高粒度\n",
    "的数据，其规律越接近于随机游走，所以发现有效模型的概率越低。 关于预测因子，在高频交易的情况下，由于不需要考虑基本面的数据，所以\n",
    "预测因子基本上也是过去的回报。为了预测一分钟的回报方向，选定过去1、3、5分钟的回报作为预测因子，模型上选用逻辑回归模型。预测因子\n",
    "可以尝试下连续型和离散型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from se2.domain.time_series import *\n",
    "from se2.domain.engine import *\n",
    "from se2.domain.account import *\n",
    "from se2.domain.common import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         start_time   open   high    low  \\\nvisible_time                                                               \n2021-05-10 21:31:00+08:00 2021-05-10 21:30:00+08:00  19.58  19.59  19.32   \n2021-05-10 21:32:00+08:00 2021-05-10 21:31:00+08:00  19.39  19.39  19.12   \n2021-05-10 21:33:00+08:00 2021-05-10 21:32:00+08:00  19.15  19.35  19.07   \n2021-05-10 21:34:00+08:00 2021-05-10 21:33:00+08:00  19.30  19.45  19.29   \n2021-05-10 21:35:00+08:00 2021-05-10 21:34:00+08:00  19.37  19.38  19.27   \n\n                           close  volume  \nvisible_time                              \n2021-05-10 21:31:00+08:00  19.41    1624  \n2021-05-10 21:32:00+08:00  19.16     387  \n2021-05-10 21:33:00+08:00  19.30     432  \n2021-05-10 21:34:00+08:00  19.41     299  \n2021-05-10 21:35:00+08:00  19.27     190  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 21:31:00+08:00</th>\n      <td>2021-05-10 21:30:00+08:00</td>\n      <td>19.58</td>\n      <td>19.59</td>\n      <td>19.32</td>\n      <td>19.41</td>\n      <td>1624</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:32:00+08:00</th>\n      <td>2021-05-10 21:31:00+08:00</td>\n      <td>19.39</td>\n      <td>19.39</td>\n      <td>19.12</td>\n      <td>19.16</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:33:00+08:00</th>\n      <td>2021-05-10 21:32:00+08:00</td>\n      <td>19.15</td>\n      <td>19.35</td>\n      <td>19.07</td>\n      <td>19.30</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:34:00+08:00</th>\n      <td>2021-05-10 21:33:00+08:00</td>\n      <td>19.30</td>\n      <td>19.45</td>\n      <td>19.29</td>\n      <td>19.41</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:35:00+08:00</th>\n      <td>2021-05-10 21:34:00+08:00</td>\n      <td>19.37</td>\n      <td>19.38</td>\n      <td>19.27</td>\n      <td>19.27</td>\n      <td>190</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = 'SPCE_STK_USD_SMART'\n",
    "start = pd.Timestamp('2021-05-09 21:00:00', tz='Asia/Shanghai')\n",
    "end = pd.Timestamp('2021-06-09 21:00:00', tz='Asia/Shanghai')\n",
    "command = HistoryDataQueryCommand(start, end, [code])\n",
    "ts_repo: TimeSeriesRepo = BeanContainer.getBean(TimeSeriesRepo)\n",
    "ts: TimeSeries = ts_repo.find_one(\"ibMinBar\")\n",
    "MIN_BAR_DF: DataFrame = ts.history_data(command, from_local=True)\n",
    "MIN_BAR_DF = MIN_BAR_DF.droplevel(level=1)\n",
    "MIN_BAR_DF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# 构造训练集和验证集\n",
    "df = MIN_BAR_DF[:'2021-05-11 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5, \"next_ret1\": next_ret1})\n",
    "train_data = df.dropna()\n",
    "train_data = train_data[train_data['next_ret1']!=0]\n",
    "train_data.loc[train_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "train_data.loc[train_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "df = MIN_BAR_DF['2021-05-11 21:00:00':'2021-05-12 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5, \"next_ret1\": next_ret1})\n",
    "test_data = df.dropna()\n",
    "test_data = test_data[test_data['next_ret1']!=0]\n",
    "test_data.loc[test_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "test_data.loc[test_data['next_ret1']<0, 'next_ret1'] = -1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhang/opt/miniconda3/envs/strategy-engine/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0, 0])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "clf.predict(X[:2, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.1, 3.5, 1.4, 0.2],\n       [4.9, 3. , 1.4, 0.2]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[9.81802911e-01, 1.81970751e-02, 1.43580537e-08],\n       [9.71729527e-01, 2.82704429e-02, 3.00353141e-08]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X[:2, :])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9733333333333334"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X, y)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.45938375350140054"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = train_data['next_ret1'].values\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X, y)\n",
    "X_t = test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = test_data['next_ret1'].values\n",
    "lr.score(X_t, y_t)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "count    696.000000\nmean       0.000310\nstd        0.007099\nmin       -0.030332\n25%       -0.003239\n50%        0.000000\n75%        0.003449\nmax        0.044397\nName: pre_ret5, dtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_data['pre_ret5'], test_data['pre_ret5']]).describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "# 尝试使用离散的变量\n",
    "new_train_data = train_data.copy()\n",
    "new_train_data.loc[:,'pre_ret1'] = pd.qcut(new_train_data['pre_ret1'], 2, labels=[-1, 1])\n",
    "new_train_data.loc[:,'pre_ret3'] = pd.qcut(new_train_data['pre_ret3'], 2, labels=[-1, 1])\n",
    "new_train_data.loc[:,'pre_ret5'] = pd.qcut(new_train_data['pre_ret5'], 2, labels=[-1, 1])\n",
    "\n",
    "new_test_data = test_data.copy()\n",
    "new_test_data.loc[:,'pre_ret1'] = pd.qcut(new_test_data['pre_ret1'], 2, labels=[-1, 1])\n",
    "new_test_data.loc[:,'pre_ret3'] = pd.qcut(new_test_data['pre_ret3'], 2, labels=[-1, 1])\n",
    "new_test_data.loc[:,'pre_ret5'] = pd.qcut(new_test_data['pre_ret5'], 2, labels=[-1, 1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5210084033613446"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = new_train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = new_train_data['next_ret1'].values\n",
    "lr = LogisticRegression(random_state=0)\n",
    "lr.fit(X, y)\n",
    "X_t = new_test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = new_test_data['next_ret1'].values\n",
    "lr.score(X_t, y_t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         start_time   open   high    low  \\\nvisible_time                                                               \n2021-05-10 21:31:00+08:00 2021-05-10 21:30:00+08:00  19.58  19.59  19.32   \n2021-05-10 21:32:00+08:00 2021-05-10 21:31:00+08:00  19.39  19.39  19.12   \n2021-05-10 21:33:00+08:00 2021-05-10 21:32:00+08:00  19.15  19.35  19.07   \n2021-05-10 21:34:00+08:00 2021-05-10 21:33:00+08:00  19.30  19.45  19.29   \n2021-05-10 21:35:00+08:00 2021-05-10 21:34:00+08:00  19.37  19.38  19.27   \n...                                             ...    ...    ...    ...   \n2021-05-11 03:56:00+08:00 2021-05-11 03:55:00+08:00  17.92  17.97  17.91   \n2021-05-11 03:57:00+08:00 2021-05-11 03:56:00+08:00  17.97  17.98  17.97   \n2021-05-11 03:58:00+08:00 2021-05-11 03:57:00+08:00  17.98  17.98  17.90   \n2021-05-11 03:59:00+08:00 2021-05-11 03:58:00+08:00  17.91  17.94  17.90   \n2021-05-11 04:00:00+08:00 2021-05-11 03:59:00+08:00  17.94  17.98  17.93   \n\n                           close  volume  \nvisible_time                              \n2021-05-10 21:31:00+08:00  19.41    1624  \n2021-05-10 21:32:00+08:00  19.16     387  \n2021-05-10 21:33:00+08:00  19.30     432  \n2021-05-10 21:34:00+08:00  19.41     299  \n2021-05-10 21:35:00+08:00  19.27     190  \n...                          ...     ...  \n2021-05-11 03:56:00+08:00  17.96     875  \n2021-05-11 03:57:00+08:00  17.98     481  \n2021-05-11 03:58:00+08:00  17.91    1459  \n2021-05-11 03:59:00+08:00  17.94     489  \n2021-05-11 04:00:00+08:00  17.97    1426  \n\n[390 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 21:31:00+08:00</th>\n      <td>2021-05-10 21:30:00+08:00</td>\n      <td>19.58</td>\n      <td>19.59</td>\n      <td>19.32</td>\n      <td>19.41</td>\n      <td>1624</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:32:00+08:00</th>\n      <td>2021-05-10 21:31:00+08:00</td>\n      <td>19.39</td>\n      <td>19.39</td>\n      <td>19.12</td>\n      <td>19.16</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:33:00+08:00</th>\n      <td>2021-05-10 21:32:00+08:00</td>\n      <td>19.15</td>\n      <td>19.35</td>\n      <td>19.07</td>\n      <td>19.30</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:34:00+08:00</th>\n      <td>2021-05-10 21:33:00+08:00</td>\n      <td>19.30</td>\n      <td>19.45</td>\n      <td>19.29</td>\n      <td>19.41</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:35:00+08:00</th>\n      <td>2021-05-10 21:34:00+08:00</td>\n      <td>19.37</td>\n      <td>19.38</td>\n      <td>19.27</td>\n      <td>19.27</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:56:00+08:00</th>\n      <td>2021-05-11 03:55:00+08:00</td>\n      <td>17.92</td>\n      <td>17.97</td>\n      <td>17.91</td>\n      <td>17.96</td>\n      <td>875</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:57:00+08:00</th>\n      <td>2021-05-11 03:56:00+08:00</td>\n      <td>17.97</td>\n      <td>17.98</td>\n      <td>17.97</td>\n      <td>17.98</td>\n      <td>481</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:58:00+08:00</th>\n      <td>2021-05-11 03:57:00+08:00</td>\n      <td>17.98</td>\n      <td>17.98</td>\n      <td>17.90</td>\n      <td>17.91</td>\n      <td>1459</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 03:59:00+08:00</th>\n      <td>2021-05-11 03:58:00+08:00</td>\n      <td>17.91</td>\n      <td>17.94</td>\n      <td>17.90</td>\n      <td>17.94</td>\n      <td>489</td>\n    </tr>\n    <tr>\n      <th>2021-05-11 04:00:00+08:00</th>\n      <td>2021-05-11 03:59:00+08:00</td>\n      <td>17.94</td>\n      <td>17.98</td>\n      <td>17.93</td>\n      <td>17.97</td>\n      <td>1426</td>\n    </tr>\n  </tbody>\n</table>\n<p>390 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_BAR_DF[:'2021-05-11 21:00:00']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data score with svc:0.5688622754491018\n",
      "train data score with lr:0.562874251497006\n",
      "test data score with svc:0.547752808988764\n",
      "test data score with lr:0.5224719101123596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "discretization_count = 2\n",
    "labels = [-1, 1]\n",
    "\n",
    "df = MIN_BAR_DF[:'2021-05-11 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "pre_ret10 = np.log(df['close'] / df['close'].shift(10))\n",
    "pre_volume1 = df['volume']\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5,\n",
    "                   \"pre_volume1\": pre_volume1,\n",
    "                   \"pre_ret10\": pre_ret10,\n",
    "                   \"next_ret1\": next_ret1})\n",
    "train_data = df.dropna()\n",
    "train_data = train_data[train_data['next_ret1']!=0]\n",
    "train_data.loc[train_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "train_data.loc[train_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "df = MIN_BAR_DF['2021-05-11 21:00:00':'2021-05-12 21:00:00']\n",
    "pre_ret1 = np.log(df['close'] / df['close'].shift(1))\n",
    "pre_ret3 = np.log(df['close'] / df['close'].shift(3))\n",
    "pre_ret5 = np.log(df['close'] / df['close'].shift(5))\n",
    "pre_ret10 = np.log(df['close'] / df['close'].shift(10))\n",
    "pre_volume1 = df['volume']\n",
    "next_ret1 = np.log(df['close'].shift(-1) / df['close'])\n",
    "df = pd.DataFrame({\"pre_ret1\": pre_ret1, \"pre_ret3\": pre_ret3, \"pre_ret5\":pre_ret5,\n",
    "                   \"pre_volume1\": pre_volume1,\n",
    "                   \"pre_ret10\": pre_ret10,\n",
    "                   \"next_ret1\": next_ret1})\n",
    "test_data = df.dropna()\n",
    "test_data = test_data[test_data['next_ret1']!=0]\n",
    "test_data.loc[test_data['next_ret1']>0, 'next_ret1'] = 1\n",
    "test_data.loc[test_data['next_ret1']<0, 'next_ret1'] = -1\n",
    "\n",
    "\n",
    "new_train_data = train_data.copy()\n",
    "new_train_data.loc[:,'pre_ret1'] = pd.qcut(new_train_data['pre_ret1'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret3'] = pd.qcut(new_train_data['pre_ret3'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret5'] = pd.qcut(new_train_data['pre_ret5'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_volume1'] = pd.qcut(new_train_data['pre_volume1'], discretization_count, labels=labels)\n",
    "new_train_data.loc[:,'pre_ret10'] = pd.qcut(new_train_data['pre_ret10'], discretization_count, labels=labels)\n",
    "\n",
    "new_test_data = test_data.copy()\n",
    "new_test_data.loc[:,'pre_ret1'] = pd.qcut(new_test_data['pre_ret1'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret3'] = pd.qcut(new_test_data['pre_ret3'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret5'] = pd.qcut(new_test_data['pre_ret5'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_volume1'] = pd.qcut(new_test_data['pre_volume1'], discretization_count, labels=labels)\n",
    "new_test_data.loc[:,'pre_ret10'] = pd.qcut(new_test_data['pre_ret10'], discretization_count, labels=labels)\n",
    "\n",
    "\n",
    "X = new_train_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y = new_train_data['next_ret1'].values\n",
    "model = SVC()\n",
    "model.fit(X, y)\n",
    "print(\"train data score with svc:{}\".format(model.score(X, y)))\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X, y)\n",
    "print(\"train data score with lr:{}\".format(model2.score(X, y)))\n",
    "X_t = new_test_data[['pre_ret1','pre_ret3', 'pre_ret5']].values\n",
    "y_t = new_test_data['next_ret1'].values\n",
    "print(\"test data score with svc:{}\".format(model.score(X_t, y_t)))\n",
    "print(\"test data score with lr:{}\".format(model2.score(X_t, y_t)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         start_time   open   high    low  \\\nvisible_time                                                               \n2021-05-10 21:31:00+08:00 2021-05-10 21:30:00+08:00  19.58  19.59  19.32   \n2021-05-10 21:32:00+08:00 2021-05-10 21:31:00+08:00  19.39  19.39  19.12   \n2021-05-10 21:33:00+08:00 2021-05-10 21:32:00+08:00  19.15  19.35  19.07   \n2021-05-10 21:34:00+08:00 2021-05-10 21:33:00+08:00  19.30  19.45  19.29   \n2021-05-10 21:35:00+08:00 2021-05-10 21:34:00+08:00  19.37  19.38  19.27   \n...                                             ...    ...    ...    ...   \n2021-06-09 03:56:00+08:00 2021-06-09 03:55:00+08:00  37.50  37.54  37.44   \n2021-06-09 03:57:00+08:00 2021-06-09 03:56:00+08:00  37.44  37.57  37.42   \n2021-06-09 03:58:00+08:00 2021-06-09 03:57:00+08:00  37.53  37.58  37.49   \n2021-06-09 03:59:00+08:00 2021-06-09 03:58:00+08:00  37.53  37.61  37.52   \n2021-06-09 04:00:00+08:00 2021-06-09 03:59:00+08:00  37.55  37.63  37.51   \n\n                           close  volume  \nvisible_time                              \n2021-05-10 21:31:00+08:00  19.41    1624  \n2021-05-10 21:32:00+08:00  19.16     387  \n2021-05-10 21:33:00+08:00  19.30     432  \n2021-05-10 21:34:00+08:00  19.41     299  \n2021-05-10 21:35:00+08:00  19.27     190  \n...                          ...     ...  \n2021-06-09 03:56:00+08:00  37.45     720  \n2021-06-09 03:57:00+08:00  37.52     777  \n2021-06-09 03:58:00+08:00  37.53     893  \n2021-06-09 03:59:00+08:00  37.56     905  \n2021-06-09 04:00:00+08:00  37.55    1846  \n\n[8190 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 21:31:00+08:00</th>\n      <td>2021-05-10 21:30:00+08:00</td>\n      <td>19.58</td>\n      <td>19.59</td>\n      <td>19.32</td>\n      <td>19.41</td>\n      <td>1624</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:32:00+08:00</th>\n      <td>2021-05-10 21:31:00+08:00</td>\n      <td>19.39</td>\n      <td>19.39</td>\n      <td>19.12</td>\n      <td>19.16</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:33:00+08:00</th>\n      <td>2021-05-10 21:32:00+08:00</td>\n      <td>19.15</td>\n      <td>19.35</td>\n      <td>19.07</td>\n      <td>19.30</td>\n      <td>432</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:34:00+08:00</th>\n      <td>2021-05-10 21:33:00+08:00</td>\n      <td>19.30</td>\n      <td>19.45</td>\n      <td>19.29</td>\n      <td>19.41</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 21:35:00+08:00</th>\n      <td>2021-05-10 21:34:00+08:00</td>\n      <td>19.37</td>\n      <td>19.38</td>\n      <td>19.27</td>\n      <td>19.27</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-06-09 03:56:00+08:00</th>\n      <td>2021-06-09 03:55:00+08:00</td>\n      <td>37.50</td>\n      <td>37.54</td>\n      <td>37.44</td>\n      <td>37.45</td>\n      <td>720</td>\n    </tr>\n    <tr>\n      <th>2021-06-09 03:57:00+08:00</th>\n      <td>2021-06-09 03:56:00+08:00</td>\n      <td>37.44</td>\n      <td>37.57</td>\n      <td>37.42</td>\n      <td>37.52</td>\n      <td>777</td>\n    </tr>\n    <tr>\n      <th>2021-06-09 03:58:00+08:00</th>\n      <td>2021-06-09 03:57:00+08:00</td>\n      <td>37.53</td>\n      <td>37.58</td>\n      <td>37.49</td>\n      <td>37.53</td>\n      <td>893</td>\n    </tr>\n    <tr>\n      <th>2021-06-09 03:59:00+08:00</th>\n      <td>2021-06-09 03:58:00+08:00</td>\n      <td>37.53</td>\n      <td>37.61</td>\n      <td>37.52</td>\n      <td>37.56</td>\n      <td>905</td>\n    </tr>\n    <tr>\n      <th>2021-06-09 04:00:00+08:00</th>\n      <td>2021-06-09 03:59:00+08:00</td>\n      <td>37.55</td>\n      <td>37.63</td>\n      <td>37.51</td>\n      <td>37.55</td>\n      <td>1846</td>\n    </tr>\n  </tbody>\n</table>\n<p>8190 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从上面的实验结果，在不对模型进行进一步调优的情况下，使用预测分钟的涨跌没有表现出显著性。显著性\n",
    "# 的检验使用二项分布，在n次独立重复实验中恰好出现k次的概率是(n!/k!(n-k)!)p^k(1-p)^k。\n",
    "# 下面考虑时间粒度更大的数据的预测\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "                           pre_ret1  std_pre_ret1  pre_ret5  std_pre_ret5  \\\nvisible_time                                                                \n2021-05-10 22:01:00+08:00 -0.005405      0.000029 -0.008097      0.000066   \n2021-05-10 22:02:00+08:00  0.003247      0.000011 -0.009142      0.000084   \n2021-05-10 22:03:00+08:00 -0.002705      0.000007 -0.007018      0.000049   \n2021-05-10 22:04:00+08:00 -0.002712      0.000007 -0.008653      0.000075   \n2021-05-10 22:05:00+08:00  0.005417      0.000029 -0.002159      0.000005   \n\n                           pre_ret10  std_pre_ret10  pre_ret20  std_pre_ret20  \\\nvisible_time                                                                    \n2021-05-10 22:01:00+08:00  -0.018792       0.000353  -0.023568       0.000555   \n2021-05-10 22:02:00+08:00  -0.013416       0.000180  -0.022437       0.000503   \n2021-05-10 22:03:00+08:00  -0.015054       0.000227  -0.026198       0.000686   \n2021-05-10 22:04:00+08:00  -0.012416       0.000154  -0.028910       0.000836   \n2021-05-10 22:05:00+08:00  -0.005925       0.000035  -0.024020       0.000577   \n\n                           pre_ret30  std_pre_ret30  next_ret10  \nvisible_time                                                     \n2021-05-10 22:01:00+08:00  -0.050724       0.002573    0.001083  \n2021-05-10 22:02:00+08:00  -0.034514       0.001191    0.009142  \n2021-05-10 22:03:00+08:00  -0.044499       0.001980    0.013986  \n2021-05-10 22:04:00+08:00  -0.052894       0.002798    0.013488  \n2021-05-10 22:05:00+08:00  -0.040238       0.001619    0.008607  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pre_ret1</th>\n      <th>std_pre_ret1</th>\n      <th>pre_ret5</th>\n      <th>std_pre_ret5</th>\n      <th>pre_ret10</th>\n      <th>std_pre_ret10</th>\n      <th>pre_ret20</th>\n      <th>std_pre_ret20</th>\n      <th>pre_ret30</th>\n      <th>std_pre_ret30</th>\n      <th>next_ret10</th>\n    </tr>\n    <tr>\n      <th>visible_time</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-05-10 22:01:00+08:00</th>\n      <td>-0.005405</td>\n      <td>0.000029</td>\n      <td>-0.008097</td>\n      <td>0.000066</td>\n      <td>-0.018792</td>\n      <td>0.000353</td>\n      <td>-0.023568</td>\n      <td>0.000555</td>\n      <td>-0.050724</td>\n      <td>0.002573</td>\n      <td>0.001083</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 22:02:00+08:00</th>\n      <td>0.003247</td>\n      <td>0.000011</td>\n      <td>-0.009142</td>\n      <td>0.000084</td>\n      <td>-0.013416</td>\n      <td>0.000180</td>\n      <td>-0.022437</td>\n      <td>0.000503</td>\n      <td>-0.034514</td>\n      <td>0.001191</td>\n      <td>0.009142</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 22:03:00+08:00</th>\n      <td>-0.002705</td>\n      <td>0.000007</td>\n      <td>-0.007018</td>\n      <td>0.000049</td>\n      <td>-0.015054</td>\n      <td>0.000227</td>\n      <td>-0.026198</td>\n      <td>0.000686</td>\n      <td>-0.044499</td>\n      <td>0.001980</td>\n      <td>0.013986</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 22:04:00+08:00</th>\n      <td>-0.002712</td>\n      <td>0.000007</td>\n      <td>-0.008653</td>\n      <td>0.000075</td>\n      <td>-0.012416</td>\n      <td>0.000154</td>\n      <td>-0.028910</td>\n      <td>0.000836</td>\n      <td>-0.052894</td>\n      <td>0.002798</td>\n      <td>0.013488</td>\n    </tr>\n    <tr>\n      <th>2021-05-10 22:05:00+08:00</th>\n      <td>0.005417</td>\n      <td>0.000029</td>\n      <td>-0.002159</td>\n      <td>0.000005</td>\n      <td>-0.005925</td>\n      <td>0.000035</td>\n      <td>-0.024020</td>\n      <td>0.000577</td>\n      <td>-0.040238</td>\n      <td>0.001619</td>\n      <td>0.008607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRED = [1, 5, 10, 20, 30]\n",
    "N = 10\n",
    "# 按天计算预测因子（过去的不同时间粒度回报）和被预测变量（未来一段时间的回报）\n",
    "\n",
    "def calc_ret(daily_df: DataFrame):\n",
    "    if len(daily_df)<=0:\n",
    "        return None\n",
    "    ret_map = {}\n",
    "    for k in PRED:\n",
    "        ret_map[\"pre_ret\"+str(k)] = np.log(daily_df['close'] / daily_df['close'].shift(k))\n",
    "        ret_map[\"std_pre_ret\"+str(k)] = np.power(np.log(daily_df['close'] / daily_df['close'].shift(k)),2)\n",
    "    ret_map['next_ret'+str(N)] = np.log(daily_df['close'].shift(-N) / daily_df['close'])\n",
    "    df = pd.DataFrame(ret_map).dropna()\n",
    "    # 去掉未来回报为0的情况,因为被预测变量是二元离散变量\n",
    "    df = df[df['next_ret'+str(N)]!=0]\n",
    "    return df\n",
    "\n",
    "rets = MIN_BAR_DF.groupby(pd.Grouper(freq='1D',origin=pd.Timestamp(\"21:00:00\", tz='Asia/Shanghai'))).apply(calc_ret).dropna()\n",
    "rets = rets.droplevel(level=0)\n",
    "rets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "# 因子数据的离散化配置， 不同的离散化方式会对结果产生影响\n",
    "# 下面尝试三种不同的离散化方式\n",
    "factor_disc_config = {\n",
    "    \"2_0\":{\n",
    "        \"bins\":[-100, 0, 100],\n",
    "        'labels':[-1, 1]\n",
    "    },\n",
    "    \"2_q\":{\n",
    "        \"qc\":2,\n",
    "        'labels':[-1, 1]\n",
    "    },\n",
    "    \"4_q\":{\n",
    "        \"qc\":4,\n",
    "        'labels':[-2, -1, 1, 2]\n",
    "    }\n",
    "}\n",
    "next_ret_key = 'next_ret'+str(N)\n",
    "rets.loc[rets[next_ret_key]>0, next_ret_key+\"_disc\"] = 1\n",
    "rets.loc[rets[next_ret_key]<0, next_ret_key+\"_disc\"] = -1\n",
    "for k in PRED:\n",
    "    for disc_key in factor_disc_config.keys():\n",
    "        key = 'pre_ret'+str(k)\n",
    "        new_key = \"pre_ret\"+str(k)+\"_disc\"+disc_key\n",
    "        conf = factor_disc_config[disc_key]\n",
    "        if 'bins' in conf:\n",
    "            rets.loc[:, new_key] = pd.cut(rets[key], conf['bins'], labels=conf['labels'])\n",
    "        else:\n",
    "            rets.loc[:, new_key] = pd.qcut(rets[key], conf['qc'], labels=conf['labels'])\n",
    "\n",
    "        key = 'std_pre_ret'+str(k)\n",
    "        new_key = \"std_pre_ret\"+str(k)+\"_disc\"+disc_key\n",
    "        conf = factor_disc_config[disc_key]\n",
    "        if 'bins' in conf:\n",
    "            rets.loc[:, new_key] = pd.cut(rets[key], conf['bins'], labels=conf['labels'])\n",
    "        else:\n",
    "            rets.loc[:, new_key] = pd.qcut(rets[key], conf['qc'], labels=conf['labels'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "split_index = int(len(rets) / 2)\n",
    "TRAIN_DATA = rets.iloc[ :split_index]\n",
    "TEST_DATA = rets.iloc[split_index: ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "data": {
      "text/plain": "{'all': {'svc_train_data': 0.5518497757847534,\n  'lr_train_data': 0.5134529147982063,\n  'svc_test_data': 0.5381165919282511,\n  'lr_test_data': 0.5302690582959642},\n 'all_disc2_0': {'svc_train_data': 0.5291479820627802,\n  'lr_train_data': 0.5252242152466368,\n  'svc_test_data': 0.5196188340807175,\n  'lr_test_data': 0.5109304932735426}}"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型适配\n",
    "# 为了方便对比，实验次数应该是模型数量跟因子的笛卡尔积\n",
    "tests_confg = {\n",
    "    # \"all\":[\"pre_ret1\", \"pre_ret5\", \"pre_ret10\", \"pre_ret20\"],\n",
    "    # \"all_disc2_0\":[\"pre_ret1_disc2_0\", \"pre_ret5_disc2_0\", 'pre_ret10_disc2_0', 'pre_ret20_disc2_0'],\n",
    "    # \"all_disc2_q\":[\"pre_ret1_disc2_q\", \"pre_ret5_disc2_q\", 'pre_ret10_disc2_q', 'pre_ret20_disc2_q'],\n",
    "    # \"all_disc4_q\":[\"pre_ret1_disc4_q\", \"pre_ret5_disc4_q\", 'pre_ret10_disc4_q', 'pre_ret20_disc4_q']\n",
    "    \"all\":[\"pre_ret5\",'pre_ret10'],\n",
    "    \"all_disc2_0\":[\"pre_ret5_disc2_0\", \"pre_ret10_disc2_0\"],\n",
    "    # \"all_disc4_q\":[\"pre_ret5_disc4_q\", \"pre_ret10_disc4_q\", 'pre_ret20_disc4_q', 'pre_ret30_disc4_q'],\n",
    "    # \"all_with_std\":[\"pre_ret5\", \"pre_ret10\", \"std_pre_ret5\", \"std_pre_ret10\"],\n",
    "    # \"all_with_std2_q\":[\"pre_ret5_disc2_q\", \"pre_ret10_disc2_q\", \"std_pre_ret5_disc2_q\", \"std_pre_ret10_disc2_q\"],\n",
    "    # \"all_with_std2_q\":[\"pre_ret5_disc2_0\", \"pre_ret10_disc2_0\", \"std_pre_ret5_disc2_0\", \"std_pre_ret10_disc2_0\"],\n",
    "    # \"all_disc2_0\":[\"pre_ret5_disc2_0\", 'pre_ret10_disc2_0'],\n",
    "    # \"all_disc2_q\":[\"pre_ret5_disc2_q\", 'pre_ret10_disc2_q'],\n",
    "    # \"all_disc4_q\":[\"pre_ret5_disc4_q\", 'pre_ret10_disc4_q']\n",
    "}\n",
    "predicted_key = 'next_ret10_disc'\n",
    "\n",
    "res = {}\n",
    "for factor_key in tests_confg.keys():\n",
    "    scores = {}\n",
    "    factors = tests_confg[factor_key]\n",
    "    X = TRAIN_DATA[factors].values\n",
    "    y = TRAIN_DATA[predicted_key].values\n",
    "    model = SVC()\n",
    "    model.fit(X, y)\n",
    "    scores['svc_train_data'] = model.score(X, y)\n",
    "    model2 = LogisticRegression()\n",
    "    model2.fit(X, y)\n",
    "    scores['lr_train_data'] = model2.score(X, y)\n",
    "    X_t = TEST_DATA[factors].values\n",
    "    y_t = TEST_DATA[predicted_key].values\n",
    "    scores['svc_test_data'] = model.score(X_t, y_t)\n",
    "    scores['lr_test_data'] = model2.score(X_t, y_t)\n",
    "\n",
    "    res[factor_key] = scores\n",
    "\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 从上面的实验看来，无论是使用离散的预测因子，还是连续的预测因子。无论是使用SVM模型，还是\n",
    "# 逻辑回归模型。 无论是用多长时间区间的历史回报数据来预测未来任意时间区间的回报数据（实验尝试了对未来1分钟、5分钟、10分钟的\n",
    "# 的回报方向进行预测，结果都是不显著的）。猜想原因是因为因子维度太单一导致的\n",
    "# 使用连续因子的结果会略微好于离散因子，也许是因为连续因子能够提供更多的信息，这些信息\n",
    "# 减少的不确定性多余增加的噪音。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}